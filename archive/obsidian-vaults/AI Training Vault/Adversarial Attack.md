
Any attempt to make an AI system do something other than what it was intended for. 



* Non-Physical Attacks
	* Introducing minor perturbations to make images classify as something they're not is one example. 
	* Stickers whose application prevents AI from recognizing a stop sign as such. 
	* 
* Physical Attacks
	* Glasses that make facial recognition classify someone as someone they're not. 

## Fighting Attacks
[[Adversarial Defenses]]